Introduction
There are many metrics that you may want to keep track of in Kubernetes: available node CPU/Memory, number of running Pods vs. desired Pods for Deployments, errors and warnings, etc. There are several built-in mechanisms available to make monitoring and debugging applications easier. You can also leverage purpose-built monitoring systems that run in Pods. Kubernetes has their own basic monitoring solution called Metrics Server. You will use Metrics Server later in this Lab Step. You can also use more complete metrics pipelines, such as Prometheus, but that is beyond the scope of this Lab. 

 

Instructions
1. Use the get command to ensure all Pods have all containers running:

kubectl get pods --all-namespaces

ubuntu@ip-10-0-128-5:~$ kubectl get pods --all-namespaces
NAMESPACE     NAME                                                               READY   STATUS    RESTARTS   AGE
kube-system   calico-etcd-vw7l6                                                  1/1     Running   0          73m
kube-system   calico-kube-controllers-5dcc459c88-82whc                           1/1     Running   0          74m
kube-system   calico-node-4ddqt                                                  2/2     Running   1          72m
kube-system   calico-node-jjv85                                                  2/2     Running   2          72m
kube-system   calico-node-n74d4                                                  2/2     Running   2          74m
kube-system   coredns-86c58d9df4-6wcx4                                           1/1     Running   0          74m
kube-system   coredns-86c58d9df4-g5422                                           1/1     Running   0          74m
kube-system   etcd-ip-10-0-20-85.us-west-2.compute.internal                      1/1     Running   0          73m
kube-system   kube-apiserver-ip-10-0-20-85.us-west-2.compute.internal            1/1     Running   0          73m
kube-system   kube-controller-manager-ip-10-0-20-85.us-west-2.compute.internal   1/1     Running   0          73m
kube-system   kube-proxy-4t45b                                                   1/1     Running   0          72m
kube-system   kube-proxy-gwxx7                                                   1/1     Running   0          74m
kube-system   kube-proxy-mghwx                                                   1/1     Running   0          72m
kube-system   kube-scheduler-ip-10-0-20-85.us-west-2.compute.internal            1/1     Running   0          73m
kube-system   kubernetes-dashboard-59756dbcc8-xqdvc                              1/1     Running   0          74m
logs          counter                                                            2/2     Running   0          13m
logs          pod-logs                                                           2/2     Running   0          36m
logs          webserver-logs                                                     1/1     Running   0          33m

The READY column separates the number of containers that are ready and the number of containers in a Pod by a slash. You can quickly get a view off all the Pods in the cluster by adding the --all-namespaces option to get. Similarly for any other Resource type, you can use get to quickly get a view of those Resources. For example, the output for Deployments lists the desired and actual number of Pods that are in each Deployment.

To get more information you can use some commands you have used extensively in this Lab:

describe which includes information about the resource itself as well as related resources and events
logs for diagnosing any failures related to Pods and containers
The get command can also be used to view complete configuration details by adding instructing the command to output in YAML format (-o yaml). This can help you diagnose any suspected configuration issues.

 

2. List all the events in the logs namespace:

kubectl get events -n logs

ubuntu@ip-10-0-128-5:~$ kubectl get events -n logs
LAST SEEN   TYPE     REASON                 KIND      MESSAGE
15m         Normal   Scheduled              Pod       Successfully assigned logs/counter to ip-10-0-18-112.us-west-2.compute.internal
15m         Normal   Pulling                Pod       pulling image "busybox"
15m         Normal   Pulled                 Pod       Successfully pulled image "busybox"
15m         Normal   Created                Pod       Created container
15m         Normal   Started                Pod       Started container
15m         Normal   Pulling                Pod       pulling image "lrakai/fluentd-s3:latest"
15m         Normal   Pulled                 Pod       Successfully pulled image "lrakai/fluentd-s3:latest"
15m         Normal   Created                Pod       Created container
15m         Normal   Started                Pod       Started container
39m         Normal   Scheduled              Pod       Successfully assigned logs/pod-logs to ip-10-0-23-47.us-west-2.compute.internal
39m         Normal   Pulling                Pod       pulling image "busybox:1.30.1"
38m         Normal   Pulled                 Pod       Successfully pulled image "busybox:1.30.1"
38m         Normal   Created                Pod       Created container
38m         Normal   Started                Pod       Started container
38m         Normal   Pulled                 Pod       Container image "busybox:1.30.1" already present on machine
38m         Normal   Created                Pod       Created container
38m         Normal   Started                Pod       Started container
35m         Normal   Scheduled              Pod       Successfully assigned logs/webserver-logs to ip-10-0-18-112.us-west-2.compute.internal
35m         Normal   Pulling                Pod       pulling image "httpd:2.4.38-alpine"
35m         Normal   Pulled                 Pod       Successfully pulled image "httpd:2.4.38-alpine"
35m         Normal   Created                Pod       Created container
35m         Normal   Started                Pod       Started container
34m         Normal   EnsuringLoadBalancer   Service   Ensuring load balancer
34m         Normal   EnsuredLoadBalancer    Service   Ensured load balancer


You can retrieve events for individual resources by using the describe command, but the get events command allows you to see all events in sequence. Events are namespaced so you can limit your search by Namespace. To get additional information, you can instruct get to output in wide format (-o wide).

 

3. Enter the following command to see how to use the top command to monitor node and Pod resource utilization:

kubectl top
alt

The kubectl top command is in the same spirit as the top command for Unix-based operating systems. As the output states, the top command depends on a properly configured system for collecting the usage information. Heapster is a deprecated tool for collecting metrics. Metrics Server is the supported tool that Kubernetes provides. Metrics Server implements the Kubernetes metrics API. Other metric pipelines can also implement the metrics API to work with top and provide additional functionality, e.g. Prometheus, however they are outside of the scope of this Lab.

Metrics Server is not installed so top will not work if you try to use it now.

 

4. Download the Metrics Server manifest files and create the associated Resources:

wget -O /tmp/metrics-server.zip https://github.com/cloudacademy/metrics-server/archive/master.zip
sudo apt install unzip
unzip -q -d /tmp /tmp/metrics-server.zip
kubectl create -f /tmp/metrics-server-master/deploy/1.8+/

ubuntu@ip-10-0-128-5:~$ ls /tmp/metrics-server-master/deploy/1.8+/
aggregated-metrics-reader.yaml  metrics-server-deployment.yaml
auth-delegator.yaml             metrics-server-service.yaml
auth-reader.yaml                resource-reader.yaml
metrics-apiservice.yaml


ubuntu@ip-10-0-128-5:~$ kubectl create -f /tmp/metrics-server-master/deploy/1.8+/
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created
rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created
serviceaccount/metrics-server created
deployment.extensions/metrics-server created
service/metrics-server created
clusterrole.rbac.authorization.k8s.io/system:metrics-server created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created

Amongst the role and rolebinding resources that give Metrics Server the permisison it need to collect metrics, the metrics API (v1beta1.metrics.k8s.io) is registered. A deployment and service for accessing Metrics Server are also created. You are now gathering node and Pod resource utilization metrics with Metrics Server.

 

5. Use top to view resource utilization metrics for the cluster's nodes:

kubectl top node

ubuntu@ip-10-0-128-5:~$ kubectl top node
NAME                                        CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
ip-10-0-18-112.us-west-2.compute.internal   89m          4%     596Mi           69%
ip-10-0-20-85.us-west-2.compute.internal    218m         10%    1566Mi          41%
ip-10-0-23-47.us-west-2.compute.internal    77m          3%     518Mi           60%


The output displays CPU usage in cores and %. The master and nodes both have 2 CPU cores available. The CPU(cores) column would have a maximum value of 2000m (2000 milliCPU cores = 2 CPU cores). The CPU metrics indicate that the cluster is not under CPU pressure. The MEMORY columns indicate that there is less than 50% memory available on the nodes. That is not a problem if workloads on the cluster are stable. As new Pods are added you should monitor the memory pressure. You should also set CPU and memory limits and requests in your Pod containers to avoid an unexpected degradation in performance. Issue kubectl explain pod.spec.containers.resources for more information. 

Warning: It can take a minute for the first metrics to become available. Re-issue the command after a minute if you receive the error metrics not available yet.

 

6. Use top to view resource utilization metrics for the Pod's in the logs Namespace:

kubectl top pods -n logs

ubuntu@ip-10-0-128-5:~$ kubectl top pods -n logs
NAME             CPU(cores)   MEMORY(bytes)
counter          4m           82Mi
pod-logs         1m           1Mi
webserver-logs   1m           6Mi

From this view, you can see if there are any indications that a Pod is using an unexpected amount of resources.

 

7. Display the resource utilization of individual containers:

kubectl top pod -n logs --containers

ubuntu@ip-10-0-128-5:~$ kubectl top pods -n logs --containers
POD              NAME          CPU(cores)   MEMORY(bytes)
counter          count-agent   3m           80Mi
counter          count         2m           1Mi
pod-logs         client        1m           0Mi
pod-logs         server        1m           0Mi
webserver-logs   server        1m           6Mi

The --containers option allows you to understand the resource utilization at a finer granularity.

 

8. Use a label selector to show only resource utilizaiton for Pods with a test label:

kubectl top pod -n logs --containers -l test
alt

Label selectors make it easy to focus your search as long as you have a well-defined labeling strategy.


See if you can identify which container uses the most CPU or memory in the kube-system namespace.
ubuntu@ip-10-0-128-5:~$ kubectl top pod -n kube-system --containers
POD                                                                NAME                      CPU(cores)   MEMORY(bytes)
calico-etcd-vw7l6                                                  calico-etcd               3m           6Mi
calico-kube-controllers-5dcc459c88-82whc                           calico-kube-controllers   2m           10Mi
calico-node-4ddqt                                                  calico-node               14m          34Mi
calico-node-4ddqt                                                  install-cni               1m           3Mi
calico-node-jjv85                                                  install-cni               1m           1Mi
calico-node-jjv85                                                  calico-node               16m          33Mi
calico-node-n74d4                                                  install-cni               1m           45Mi
calico-node-n74d4                                                  calico-node               15m          18Mi
coredns-86c58d9df4-6wcx4                                           coredns                   3m           7Mi
coredns-86c58d9df4-g5422                                           coredns                   2m           8Mi
etcd-ip-10-0-20-85.us-west-2.compute.internal                      etcd                      21m          53Mi
kube-apiserver-ip-10-0-20-85.us-west-2.compute.internal            kube-apiserver            29m          410Mi
kube-controller-manager-ip-10-0-20-85.us-west-2.compute.internal   kube-controller-manager   20m          48Mi
kube-proxy-4t45b                                                   kube-proxy                2m           14Mi
kube-proxy-gwxx7                                                   kube-proxy                2m           9Mi
kube-proxy-mghwx                                                   kube-proxy                2m           13Mi
kube-scheduler-ip-10-0-20-85.us-west-2.compute.internal            kube-scheduler            6m           11Mi
kubernetes-dashboard-59756dbcc8-xqdvc                              kubernetes-dashboard      1m           12Mi
metrics-server-68d85f76bb-qz468                                    metrics-server            1m           13Mi

 ubuntu@ip-10-0-128-5:~$ kubectl cluster-info
Kubernetes master is running at https://cloudacad-apiloadb-1pjxr1lmtig8s-1529637102.us-west-2.elb.amazonaws.com:443
KubeDNS is running at https://cloudacad-apiloadb-1pjxr1lmtig8s-1529637102.us-west-2.elb.amazonaws.com:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
